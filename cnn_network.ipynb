{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport cv2\nfrom torchvision import datasets, transforms\nfrom torchvision.datasets import ImageFolder\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nfrom torch import optim, nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset \nimport torch.utils.data as utils_data\nimport IPython\nimport torchvision\n\ntraining_set = os.listdir('../input/dogs-cats-images/dog vs cat/dataset/training_set/')#/dataset/training_set/')\n\ntesting_set = os.listdir('../input/dogs-cats-images/dog vs cat/dataset/test_set/')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"size = 100\n\nModifyPics = transforms.Compose([transforms.Resize((size,size)),\n                                transforms.ToTensor(),\n                                transforms.Normalize([.5, .5, .5],\n                                                     [.5, .5, .5])])\ntrain_on_gpu = torch.cuda.is_available()\n\n\nif not train_on_gpu:\n    print(\"Cuda is NOT Avaialble... cpu usage\")\n    \nelse:\n    print(\"Cuda IS Avaialble... gpu usage\")\n    \ntorch.cuda.empty_cache()\n\ndevice = torch.device(\"cuda:0\")\n\ntrain_set =datasets.ImageFolder(\n    \"../input/dogs-cats-images/dog vs cat/dataset/training_set/\",\n    transform=ModifyPics)\n\n\ntrain_loader=torch.utils.data.DataLoader(\n    train_set,batch_size=50, \n    shuffle=True)\n\ntest_set=datasets.ImageFolder(\n    \"../input/dogs-cats-images/dog vs cat/dataset/test_set/\",\n    transform=ModifyPics)\ntest_loader=torch.utils.data.DataLoader(\n    test_set,batch_size=50,shuffle=True)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline \nbatch = next(iter(train_loader))\n\nimages, labels = batch\nprint(labels)\n# grid = torchvision.utils.make_grid(images, nrow=10)\n# plt.figure(figsize=(50,50))\n# plt.imshow(np.transpose(grid, (1,2,0)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def validation(model, validateloader, criterion):\n    \n    val_loss = 0\n    accuracy = 0\n    \n    for images, labels in iter(validateloader):\n        \n\n        images,labels=images.to(device),labels.to(device)\n        \n\n        output = model.forward(images)\n        val_loss += criterion(output, labels).item()\n\n        probabilities = torch.exp(output)\n        \n        equality = (labels.data == probabilities.max(dim=1)[1])\n        accuracy += equality.type(torch.FloatTensor).mean()\n    \n    return val_loss, accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport torch.nn.functional as F\ndevice = torch.device(\"cuda:0\")\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels=3,out_channels=128,kernel_size= 5,padding=1)\n        self.conv2 = nn.Conv2d(in_channels=128, out_channels=64,kernel_size= 5,padding =1)\n        self.conv3 = nn.Conv2d(in_channels=64,out_channels=32,kernel_size= 5, padding=1)\n        \n        self.pool = nn.MaxPool2d(2,2)\n        \n        self.fc1  = nn.Linear(9248,256)\n        self.fc2 = nn.Linear(256, 128)\n        self.fc3 = nn.Linear(128,64)\n        self.fc4 = nn.Linear(64,2)\n        self.dropout = nn.Dropout(p=0.2)\n        \n    def forward(self,x):\n        \n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        \n        x = x.view(-1,9248)\n        x = self.dropout(F.relu(self.fc1(x)))\n        x = self.dropout(F.relu(self.fc2(x)))\n        x = self.dropout(F.relu(self.fc3(x)))\n        \n        x = self.fc4(x)\n        \n        return x\n        \n        \n        \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Net()\nif train_on_gpu:\n    model.cuda()\n\nmodel.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=3e-2)\n\nepochs = 30\ntrain_losses, test_losses,accuracy_losses=[],[],[]\nfor e in range(epochs):\n    running_loss = 0\n    for images, labels in train_loader:\n        images,labels=images.to(device),labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    else:\n        validation_loss = 0\n        accuracy= 0\n        \n        with torch.no_grad():\n            validation_loss, accuracy = validation(model, train_loader, criterion)\n        \n        model.train()\n        train_losses.append(running_loss/len(test_loader))\n        test_losses.append(validation_loss/len(test_loader))\n        accuracy_losses.append(accuracy/len(test_loader))\n\n        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n              \"Validation Loss: {:.3f}.. \".format(validation_loss/len(train_loader)),\n              \"Validation Accuracy: {:.3f}%\".format(accuracy/len(train_loader)* 100))\n\n        \n        \n\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport matplotlib.pyplot as plt\n\nplt.plot(train_losses, label='Training loss')\nplt.plot(test_losses, label='Validation loss')\nplt.plot(accuracy_losses,label='Validation Accuracy')\nplt.legend(frameon=False)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n# import pygame \nfrom PIL import Image \nfrom time import sleep\nimport torchvision.transforms.functional as TF\nfile1 = \"../input/sounds/dog-sound/i_see_dog.wav\"\n\n\nfile2 = \"../input/sounds/dog-sound/i_see_cat.wav\"\n\n\nfor i in range(5):\n    images, labels = next(iter(train_loader)) \n    images,labels=images.to(device),labels.to(device)\n    output = model(images)\n    \n   \n\n    image = images[1,:]\n\n    image = image.view(3,size,-1) \n    image = image.cpu().numpy()\n    image = image /2+.05\n    plt.imshow(np.transpose(image, (1,2,0))) \n    target_value = output.data.max(1, keepdim=True)[1][1].item() \n   \n    if target_value == 1: \n       \n        dog=IPython.display.display(IPython.display.Audio(file1))\n        \n    else: \n        \n        cat=IPython.display.display(IPython.display.Audio(file2))\n        \n\n\n    plt.show()\n\n    \n\nfor i in range(5):\n    images, labels = next(iter(test_loader)) \n    images,labels=images.to(device),labels.to(device)\n    output = model(images)\n    \n    \n   \n\n    image = images[1,:]\n\n    image = image.view(3,size,-1) \n    image = image.cpu().numpy()\n    image = image /2+.05\n    plt.imshow(np.transpose(image, (1,2,0))) \n    target_value = output.data.max(1, keepdim=True)[1][1].item() \n   \n    if target_value == 1:\n       \n        \n       \n        dog=IPython.display.display(IPython.display.Audio(file1))\n        \n    else: \n       \n        cat=IPython.display.display(IPython.display.Audio(file2))\n        \n\n\n    plt.show()\n    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}